### 設定の読み込み規則（重要）
- **読み込み元**: `.env` が読み込まれます（サンプルは `env.example`）。未使用キーは無視されます。大文字/小文字は区別しません。  
```104:112:apps/backend/backend/config.py
    model_config = SettingsConfigDict(
        env_file=".env",
        extra="ignore",
        case_sensitive=False,
    )
```
- **フィールド名と環境変数名の対応**: `llm_provider` ⇔ `LLM_PROVIDER` のように、スネークケース⇔大文字アンダースコアで自動対応します。
- 以降の既定値は「1) env.example のサンプル値」「2) コード側のデフォルト値」の両方を明記します（実際は `.env` による上書きが有効）。

---

### 1) ENVIRONMENT
- 用途: 実行環境の識別（ロギング方針や運用切替のフラグに利用可能）。現時点では主にメタ情報。
- 既定値: env.example=development / コード既定="development"
- 使われ方: `apps/backend/backend/config.py` のみで保持（直接の分岐は現状なし）。
- 未設定/誤設定: 未設定なら "development"。誤設定でも致命的影響なし。
- 設定例: 本番で `"production"`。

---

### 2) LLM_PROVIDER, LLM_MODEL, LLM_TIMEOUT_MS, LLM_MAX_RETRIES, LLM_MAX_TOKENS
- 用途:
  - `LLM_PROVIDER`: LLM クライアントの選択。`openai` | `local`
- `LLM_MODEL`: 使うモデル名（例: `gpt-4o-mini` / `gpt-4.1-mini` / `gpt-5-mini` / `gpt-5-nano`）
  - `LLM_TIMEOUT_MS`: 1回の LLM 呼び出しのタイムアウト
  - `LLM_MAX_RETRIES`: LLM 呼び出しの最大リトライ回数
- 既定値:
  - env.example: `LLM_PROVIDER=openai`, `LLM_MODEL=gpt-4o-mini`, `LLM_TIMEOUT_MS=45000`, `LLM_MAX_RETRIES=1`, `LLM_MAX_TOKENS=1500`
  - コード既定: `llm_provider="openai"`, `llm_model="gpt-4o-mini"`, `llm_timeout_ms=60000`, `llm_max_retries=1`, `llm_max_tokens=900`
- 使われ方:
  - プロバイダ選択と初期化
```128:146:apps/backend/backend/providers.py
    provider = (settings.llm_provider or "").lower()
    try:
        if provider == "openai" and settings.openai_api_key:
            _LLM_INSTANCE = _llm_with_policy(_OpenAILLM(api_key=settings.openai_api_key, model=settings.llm_model))
            return _LLM_INSTANCE
        # 未対応プロバイダはローカルフォールバック
        _LLM_INSTANCE = _llm_with_policy(_LocalEchoLLM())
        return _LLM_INSTANCE
```
  - タイムアウト/リトライの適用（試行ごとにタイムアウト、指数的ではない短いバックオフ）
```99:111:apps/backend/backend/providers.py
        def complete(self, prompt: str) -> str:
            last_exc: Exception | None = None
            for attempt in range(1, max(1, settings.llm_max_retries) + 1):
                try:
                    future = _llm_executor.submit(llm.complete, prompt)
                    return future.result(timeout=settings.llm_timeout_ms / 1000.0)
                except Exception as exc:
                    last_exc = exc
                    if attempt >= max(1, settings.llm_max_retries):
                        break
                    time.sleep(0.1 * attempt)
            return ""
```
- 未設定/誤設定:
  - `LLM_PROVIDER=openai` でも `OPENAI_API_KEY` が空なら、自動で安全なローカルフォールバック（空文字を返す）に切替。
  - 失敗時は例外を投げず空文字を返す設計（上位はフォールバック前提）。
  - `LLM_MAX_TOKENS` は Responses API の `max_output_tokens`（または互換名）として使用され、JSON途中切れの防止に寄与。
- 設定例:
  - OpenAI: `LLM_PROVIDER=openai`, `LLM_MODEL=gpt-4o-mini|gpt-4.1-mini|gpt-5-mini|gpt-5-nano` など + `OPENAI_API_KEY`
  - オフライン学習/テスト: `LLM_PROVIDER=local`
  - 推論系（gpt-5-mini）を使う場合は UI から `reasoning.effort`/`text.verbosity` を指定（サーバ側は SDK 未対応項目を自動除去）

---

### 3) EMBEDDING_PROVIDER, EMBEDDING_MODEL
- 用途: ベクトル検索用の埋め込み生成のプロバイダとモデル指定。
- 既定値: env.example=`openai`/`text-embedding-3-small`、コード既定も同じ。
- 使われ方:
```162:179:apps/backend/backend/providers.py
    provider = (settings.embedding_provider or "").lower()
    if provider == "openai" and settings.openai_api_key and OpenAI is not None:
        client = OpenAI(api_key=settings.openai_api_key)
        model = settings.embedding_model
        class _OpenAIEmbedding:
            def __call__(self, texts: List[str]) -> List[List[float]]:
                ...
                resp = client.embeddings.create(model=model, input=chunk)
                ...
        return _OpenAIEmbedding()
    return SimpleEmbeddingFunction()
```
- 未設定/誤設定: OpenAI キーが無い/SDK未導入なら、決定的なダミー埋め込み（次元8）に自動フォールバック。
- 設定例: OpenAI を使う場合 `EMBEDDING_PROVIDER=openai`, `EMBEDDING_MODEL=text-embedding-3-small` か `text-embedding-3-large` など。

---

### 4) OPENAI_API_KEY
- 用途: OpenAI（LLM/Embeddings）の認証。
- 既定値: 空（必須の場合はユーザーが設定）
- 使われ方: 上記 LLM/埋め込みの分岐で参照。
- 未設定/誤設定: 自動フォールバック（LLM は local、Embeddings はダミー）。

---

 

---

### 6) （削除済み）ベクトル検索関連の環境変数
本プロジェクトではベクトル検索の環境変数は廃止されました。

---

### 7) CHROMA_PERSIST_DIR / CHROMA_SERVER_URL
- 用途:
  - `CHROMA_PERSIST_DIR`: ローカル永続ディレクトリ（サーバURL未指定時に使用）
  - `CHROMA_SERVER_URL`: リモートの Chroma サーバーを使う場合の接続先
- 既定値: env.example は `.chroma`、URL はコメントアウト（未指定）
- 使われ方:
```190:206:apps/backend/backend/providers.py
    def __init__(self, persist_directory: Optional[str] = None) -> None:
        self.persist_directory = persist_directory or settings.chroma_persist_dir
    def create_client(self) -> Any | None:
        ...
        if getattr(settings, "chroma_server_url", None):
            ...
            underlying = http_cls(host=settings.chroma_server_url)
        else:
            underlying = chromadb.PersistentClient(path=self.persist_directory)
```
- 未設定/誤設定:
  - SDK未導入/接続失敗時は軽量なインメモリ互換クライアントに自動フォールバックし、動作継続。
- 設定例:
  - ローカル永続: `CHROMA_SERVER_URL` 未設定、`CHROMA_PERSIST_DIR=.chroma`
  - リモート接続: `CHROMA_SERVER_URL=https://chroma.example`（この場合 persist は使わない）

---

### 8) SRS_DB_PATH
- 用途:
  - WordPack や記事を保存する SQLite DB の保存先
- 既定値: `.data/srs.sqlite3`（env.example/コードともに同じ）
- 使われ方:
```apps/backend/backend/store.py
# module-level singleton store (wired to settings)
store = AppSQLiteStore(db_path=settings.srs_db_path)
```
  - アプリ起動時にディレクトリ作成と DB 初期化が行われます。
- 未設定/誤設定:
  - 書き込み不可な場所はエラー要因。既定の `.data/` 配下推奨。
- 備考:
  - 旧SRS（復習）機能は削除済みで、`SRS_MAX_TODAY` などの関連環境変数も現在は使用しません。
  - `/api/sentence/check` および `/api/review/*` といった互換エンドポイントは廃止済みです。
- 設定例: `SRS_DB_PATH=.data/srs.sqlite3`

---

### 9) RATE_LIMIT_PER_MIN_IP / RATE_LIMIT_PER_MIN_USER
- 用途: API 全体のレート制限（トークンバケット、毎分補充）。IP 単位/User 単位（`X-User-Id` ヘッダ）。
- 既定値: env.example=240/240、コード既定も同じ
- 使われ方（ミドルウェアに注入）:
```42:47:apps/backend/backend/main.py
app.add_middleware(
    RateLimitMiddleware,
    ip_capacity_per_minute=settings.rate_limit_per_min_ip,
    user_capacity_per_minute=settings.rate_limit_per_min_user,
)
```
- 429 時のレスポンスヘッダ（残量など）:
```118:126:apps/backend/backend/middleware.py
response.headers.setdefault("X-RateLimit-Limit-Ip", str(self._ip_capacity))
response.headers.setdefault("X-RateLimit-Remaining-Ip", str(remaining_ip))
...
```
- 未設定/誤設定:
  - 値は1以上にクランプ。誤って 0 等を設定しても最低 1 になります。
  - User 制限は `X-User-Id` が無いと適用されない（IP 制限のみ）。
- 設定例: 公開環境で `RATE_LIMIT_PER_MIN_IP=120`, `RATE_LIMIT_PER_MIN_USER=240` など。

---

### 10) SENTRY_DSN
- 用途: Sentry にログ/例外を送信（任意）。
- 既定値: 空（無効）
- 使われ方:
```27:36:apps/backend/backend/logging.py
if settings.sentry_dsn:
    import sentry_sdk
    from sentry_sdk.integrations.logging import LoggingIntegration
    sentry_logging = LoggingIntegration(level=logging.INFO, event_level=logging.ERROR)
    sentry_sdk.init(dsn=settings.sentry_dsn, integrations=[sentry_logging])
```
- 未設定/誤設定: 未設定なら無効、初期化失敗でもアプリは継続。
- 設定例: `SENTRY_DSN=https://<public_key>@<host>/<project>`

---

### よくある組み合わせ（実運用のヒント）
- 開発（オフライン想定）:
  - `LLM_PROVIDER=local`, `EMBEDDING_PROVIDER=openai`（キー無しでもダミー動作）
- ステージング/本番（OpenAI）:
  - `LLM_PROVIDER=openai`, `LLM_MODEL=gpt-4o-mini`, `OPENAI_API_KEY=...`
  - `EMBEDDING_PROVIDER=openai`, `EMBEDDING_MODEL=text-embedding-3-small`
- 負荷制御:
（該当なし）
- 監視:
  - 必要に応じて `SENTRY_DSN` を有効化

---

- 以上、`env.example` の各変数が「どこでどう使われ、未設定時にどう振る舞うか」まで落とし込んで説明しました。さらに掘り下げたい項目（例: Azure の具体的デプロイ手順、Chroma のサーバーモード運用など）があれば言ってください。

- 主要箇所の要点
  - `.env` を読み、未使用キーは無視・大文字小文字は不問。
  - LLM と Embeddings はキー未設定でも安全にフォールバック。
（該当なし）
  - API 全体のレート制限は IP と User の二系統。
  - SQLite データベースは WordPack/記事保存専用（旧SRS設定は廃止済み）。