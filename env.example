# Backend settings
ENVIRONMENT=development
STRICT_MODE=true

# LLM providers: openai | local
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TIMEOUT_MS=45000
LLM_MAX_RETRIES=1
# WordPack は複数セクションのJSONを返すため、途中切れ防止に十分な値を推奨
# 生成が途中で途切れて「例文が空」になる場合は 1200–1800 に増やしてください
LLM_MAX_TOKENS=1500

# Embeddings
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small

# OpenAI
OPENAI_API_KEY=

 

# RAG/Chroma
RAG_ENABLED=false
RAG_TIMEOUT_MS=1500
RAG_MAX_RETRIES=2
RAG_RATE_LIMIT_PER_MIN=120
CHROMA_PERSIST_DIR=.chroma
# CHROMA_SERVER_URL=

# Auto seed on startup
AUTO_SEED_ON_STARTUP=true
# Optional JSONL paths (uncomment to seed from files)
# AUTO_SEED_WORD_JSONL=path/to/word_snippets.jsonl
# AUTO_SEED_TERMS_JSONL=path/to/domain_terms.jsonl

# SRS
SRS_DB_PATH=.data/srs.sqlite3
SRS_MAX_TODAY=5

# Operations/Observability (PR4)
# Per-IP / Per-User API rate limits (requests per minute)
RATE_LIMIT_PER_MIN_IP=240
RATE_LIMIT_PER_MIN_USER=240
# Optional: Enable Sentry by setting DSN
# SENTRY_DSN=