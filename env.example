# Backend settings
ENVIRONMENT=development
STRICT_MODE=true

# LLM providers: openai | local
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TIMEOUT_MS=45000
LLM_MAX_RETRIES=1
# WordPack は複数セクションのJSONを返すため、途中切れ防止に十分な値を推奨
# 生成が途中で途切れて「例文が空」になる場合は 1200–1800 に増やしてください
LLM_MAX_TOKENS=1500

# Embeddings
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small

# OpenAI
OPENAI_API_KEY=

 

# Chroma (optional local persistence directory)
CHROMA_PERSIST_DIR=.chroma
# CHROMA_SERVER_URL=

# Auto seed on startup
AUTO_SEED_ON_STARTUP=true
# Optional JSONL paths (uncomment to seed from files)
# AUTO_SEED_WORD_JSONL=path/to/word_snippets.jsonl
# AUTO_SEED_TERMS_JSONL=path/to/domain_terms.jsonl

# Persistence
WORDPACK_DB_PATH=.data/wordpack.sqlite3

# Operations/Observability (PR4)
# Per-IP / Per-User API rate limits (requests per minute)
RATE_LIMIT_PER_MIN_IP=240
RATE_LIMIT_PER_MIN_USER=240
# Optional: Enable Sentry by setting DSN
# SENTRY_DSN=

# Langfuse (optional)
# Enable and configure to send traces/metrics to Langfuse
LANGFUSE_ENABLED=false
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_SECRET_KEY=
# LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_RELEASE=wordpack-api@0.3.0
# If you need to debug prompt issues, enable full prompt logging to Langfuse
# CAUTION: This may include sensitive content. Keep disabled in production unless required.
# LANGFUSE_LOG_FULL_PROMPT=false
# LANGFUSE_PROMPT_MAX_CHARS=40000